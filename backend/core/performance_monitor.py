# backend/core/performance_monitor.py
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import defaultdict, deque
import json
import os

class PerformanceMonitor:
    """
    æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
    - è®°å½•å„ä¸ªæ­¥éª¤çš„è€—æ—¶
    - ç»Ÿè®¡ç¼“å­˜å‘½ä¸­ç‡
    - ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    - çº¿ç¨‹å®‰å…¨è®¾è®¡
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        self._monitor_lock = threading.RLock()
        
        # æ“ä½œè®°å½•å­˜å‚¨
        self._operations: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        
        # ç¼“å­˜ç»Ÿè®¡
        self._cache_stats = {
            'data': {'hits': 0, 'misses': 0},
            'chart': {'hits': 0, 'misses': 0},
            'analysis': {'hits': 0, 'misses': 0}
        }
        
        # ä¼šè¯ç»Ÿè®¡
        self._session_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'average_response_time': 0.0,
            'session_start': time.time()
        }
        
        print("PerformanceMonitor initialized")
    
    def track_operation(self, operation: str, duration: float, cache_hit: bool = False, 
                       metadata: Optional[Dict[str, Any]] = None):
        """è®°å½•æ“ä½œæ€§èƒ½æ•°æ®"""
        with self._monitor_lock:
            timestamp = time.time()
            record = {
                'timestamp': timestamp,
                'duration': duration,
                'cache_hit': cache_hit,
                'metadata': metadata or {}
            }
            
            self._operations[operation].append(record)
            
            # æ›´æ–°ç¼“å­˜ç»Ÿè®¡
            if operation in ['data_fetch', 'chart_generation', 'llm_analysis']:
                cache_type = operation.replace('_fetch', '').replace('_generation', '').replace('llm_', '')
                if cache_type == 'data_fetch':
                    cache_type = 'data'
                elif cache_type == 'chart_generation':
                    cache_type = 'chart'
                elif cache_type == 'llm_analysis':
                    cache_type = 'analysis'
                
                if cache_type in self._cache_stats:
                    if cache_hit:
                        self._cache_stats[cache_type]['hits'] += 1
                    else:
                        self._cache_stats[cache_type]['misses'] += 1
        
        print(f"Performance: {operation} took {duration:.2f}s {'(cache hit)' if cache_hit else ''}")
    
    def track_request(self, success: bool, total_duration: float):
        """è®°å½•å®Œæ•´è¯·æ±‚çš„ç»Ÿè®¡ä¿¡æ¯"""
        with self._monitor_lock:
            self._session_stats['total_requests'] += 1
            
            if success:
                self._session_stats['successful_requests'] += 1
            else:
                self._session_stats['failed_requests'] += 1
            
            # æ›´æ–°å¹³å‡å“åº”æ—¶é—´ï¼ˆåŠ æƒå¹³å‡ï¼‰
            current_avg = self._session_stats['average_response_time']
            total_requests = self._session_stats['total_requests']
            
            self._session_stats['average_response_time'] = (
                (current_avg * (total_requests - 1) + total_duration) / total_requests
            )
    
    def get_operation_stats(self, operation: str, minutes: int = 60) -> Dict[str, Any]:
        """è·å–æŒ‡å®šæ“ä½œçš„ç»Ÿè®¡ä¿¡æ¯"""
        with self._monitor_lock:
            if operation not in self._operations:
                return {'error': f'No data for operation: {operation}'}
            
            # è¿‡æ»¤æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„è®°å½•
            cutoff_time = time.time() - (minutes * 60)
            recent_records = [
                record for record in self._operations[operation]
                if record['timestamp'] >= cutoff_time
            ]
            
            if not recent_records:
                return {'operation': operation, 'period_minutes': minutes, 'count': 0}
            
            durations = [r['duration'] for r in recent_records]
            cache_hits = sum(1 for r in recent_records if r['cache_hit'])
            
            return {
                'operation': operation,
                'period_minutes': minutes,
                'count': len(recent_records),
                'average_duration': sum(durations) / len(durations),
                'min_duration': min(durations),
                'max_duration': max(durations),
                'cache_hit_rate': (cache_hits / len(recent_records)) * 100 if recent_records else 0,
                'cache_hits': cache_hits,
                'cache_misses': len(recent_records) - cache_hits
            }
    
    def get_cache_hit_rates(self) -> Dict[str, float]:
        """è·å–å„ç±»ç¼“å­˜çš„å‘½ä¸­ç‡"""
        with self._monitor_lock:
            hit_rates = {}
            for cache_type, stats in self._cache_stats.items():
                total = stats['hits'] + stats['misses']
                if total > 0:
                    hit_rates[cache_type] = (stats['hits'] / total) * 100
                else:
                    hit_rates[cache_type] = 0.0
            
            return hit_rates
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´çš„æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        with self._monitor_lock:
            # åŸºç¡€ä¼šè¯ç»Ÿè®¡
            session_duration = time.time() - self._session_stats['session_start']
            
            stats = {
                'session': {
                    **self._session_stats,
                    'session_duration_minutes': session_duration / 60,
                    'requests_per_minute': self._session_stats['total_requests'] / (session_duration / 60) if session_duration > 0 else 0
                },
                'cache_hit_rates': self.get_cache_hit_rates(),
                'cache_stats': dict(self._cache_stats),
                'operations': {}
            }
            
            # å„æ“ä½œçš„ç»Ÿè®¡
            key_operations = ['data_fetch', 'chart_generation', 'llm_analysis', 'report_generation']
            for operation in key_operations:
                stats['operations'][operation] = self.get_operation_stats(operation, 60)
            
            return stats
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå¯è¯»çš„æ€§èƒ½æŠ¥å‘Š"""
        stats = self.get_performance_stats()
        
        report_lines = [
            "=== AIé‡‘èåˆ†ææœåŠ¡æ€§èƒ½æŠ¥å‘Š ===",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "ğŸ“Š ä¼šè¯ç»Ÿè®¡:",
            f"  æ€»è¯·æ±‚æ•°: {stats['session']['total_requests']}",
            f"  æˆåŠŸè¯·æ±‚: {stats['session']['successful_requests']}",
            f"  å¤±è´¥è¯·æ±‚: {stats['session']['failed_requests']}",
            f"  æˆåŠŸç‡: {(stats['session']['successful_requests'] / max(stats['session']['total_requests'], 1)) * 100:.1f}%",
            f"  å¹³å‡å“åº”æ—¶é—´: {stats['session']['average_response_time']:.2f}ç§’",
            f"  è¯·æ±‚é¢‘ç‡: {stats['session']['requests_per_minute']:.1f}æ¬¡/åˆ†é’Ÿ",
            "",
            "ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡:",
        ]
        
        for cache_type, hit_rate in stats['cache_hit_rates'].items():
            cache_display = {
                'data': 'æ•°æ®è·å–',
                'chart': 'å›¾è¡¨ç”Ÿæˆ', 
                'analysis': 'AIåˆ†æ'
            }.get(cache_type, cache_type)
            
            report_lines.append(f"  {cache_display}: {hit_rate:.1f}%")
        
        report_lines.extend([
            "",
            "â±ï¸ å„æ­¥éª¤æ€§èƒ½ (æœ€è¿‘1å°æ—¶):"
        ])
        
        operation_display = {
            'data_fetch': 'æ•°æ®è·å–',
            'chart_generation': 'å›¾è¡¨ç”Ÿæˆ',
            'llm_analysis': 'AIåˆ†æ',
            'report_generation': 'æŠ¥å‘Šç”Ÿæˆ'
        }
        
        for operation, display_name in operation_display.items():
            op_stats = stats['operations'].get(operation, {})
            if op_stats.get('count', 0) > 0:
                report_lines.extend([
                    f"  {display_name}:",
                    f"    è¯·æ±‚æ¬¡æ•°: {op_stats['count']}",
                    f"    å¹³å‡è€—æ—¶: {op_stats['average_duration']:.2f}ç§’",
                    f"    æœ€å¿«: {op_stats['min_duration']:.2f}ç§’",
                    f"    æœ€æ…¢: {op_stats['max_duration']:.2f}ç§’",
                    f"    ç¼“å­˜å‘½ä¸­ç‡: {op_stats['cache_hit_rate']:.1f}%"
                ])
        
        # æ€§èƒ½å»ºè®®
        report_lines.extend([
            "",
            "ğŸ’¡ æ€§èƒ½åˆ†æ:"
        ])
        
        # åŸºäºç»Ÿè®¡æ•°æ®ç»™å‡ºå»ºè®®
        overall_hit_rate = sum(stats['cache_hit_rates'].values()) / len(stats['cache_hit_rates']) if stats['cache_hit_rates'] else 0
        
        if overall_hit_rate < 50:
            report_lines.append("  âš ï¸ ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®å¢åŠ ç¼“å­˜TTLæˆ–æ£€æŸ¥ç¼“å­˜ç­–ç•¥")
        elif overall_hit_rate > 80:
            report_lines.append("  âœ… ç¼“å­˜æ•ˆæœè‰¯å¥½ï¼Œæ€§èƒ½ä¼˜åŒ–æ˜¾è‘—")
        else:
            report_lines.append("  ğŸ“ˆ ç¼“å­˜æ•ˆæœä¸­ç­‰ï¼Œè¿˜æœ‰ä¼˜åŒ–ç©ºé—´")
        
        if stats['session']['average_response_time'] > 20:
            report_lines.append("  âš ï¸ å¹³å‡å“åº”æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®æ£€æŸ¥ç“¶é¢ˆæ­¥éª¤")
        elif stats['session']['average_response_time'] < 5:
            report_lines.append("  âœ… å“åº”æ—¶é—´ä¼˜ç§€ï¼Œç¼“å­˜æ•ˆæœæ˜¾è‘—")
        
        return "\n".join(report_lines)
    
    def save_report_to_file(self, filepath: Optional[str] = None) -> str:
        """ä¿å­˜æ€§èƒ½æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if filepath is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filepath = f"performance_report_{timestamp}.txt"
        
        report = self.generate_report()
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"Performance report saved to: {filepath}")
            return filepath
        except Exception as e:
            print(f"Error saving performance report: {e}")
            return ""
    
    def export_stats_json(self) -> str:
        """å¯¼å‡ºç»Ÿè®¡æ•°æ®ä¸ºJSONæ ¼å¼"""
        stats = self.get_performance_stats()
        
        # æ·»åŠ æ—¶é—´æˆ³
        stats['export_timestamp'] = datetime.now().isoformat()
        
        try:
            return json.dumps(stats, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"Error exporting stats to JSON: {e}")
            return "{}"
    
    def reset_stats(self):
        """é‡ç½®æ‰€æœ‰ç»Ÿè®¡æ•°æ®"""
        with self._monitor_lock:
            self._operations.clear()
            
            for cache_type in self._cache_stats:
                self._cache_stats[cache_type] = {'hits': 0, 'misses': 0}
            
            self._session_stats = {
                'total_requests': 0,
                'successful_requests': 0,
                'failed_requests': 0,
                'average_response_time': 0.0,
                'session_start': time.time()
            }
        
        print("Performance statistics reset")

# å…¨å±€æ€§èƒ½ç›‘æ§å®ä¾‹
_monitor_instance = None

def get_monitor() -> PerformanceMonitor:
    """è·å–å…¨å±€æ€§èƒ½ç›‘æ§å®ä¾‹"""
    global _monitor_instance
    if _monitor_instance is None:
        _monitor_instance = PerformanceMonitor()
    return _monitor_instance 